\section{Множества. Основные операции: проверка, добавление, удаление. Реализация списком, массивом, битовой картой}
\section{Словари и хеш-таблицы. Хеширование, хеш-функции. Коллизии хеширования}
\textbf{Хеширование}~--- процесс преобразования входных данных произвольной длины (ключа) в фиксированный размер выходных данных (хеш-код) с помощью
\textit{хеш-функции}.

\textbf{Хеш-функция}~--- функция, преобразующая массив входных данных произвольного размера в выходную строку фиксированной длины, называемую хешем.

Заметим, что так как под хешем понимается (битовая) строка фиксированной длины, то, вообще говоря, по принципу Дирихле существуют различные данные,
имеющие одинаковый хеш. Такое совпадение хешей часто называют <<коллизией хеширования>> и все алгоритмы, опирающиеся на хеш-функции, должны это
учитывать. Несмотря на это, хеш-функции широко используются в различных ветвях информатики. Рассмотрим одно из их приложений.

\subsection{Словари. Хеш-таблицы}
\textbf{Ассоциативным массивом} (словарем\footnote{Иногда конкретизируют, что словарь~--- это ассоциативный массив именно со \textit{строками} в качестве ключа.
Но как тогда объяснить, что ассоциативный массив в том же C\# называется \href{https://learn.microsoft.com/en-us/dotnet/api/system.collections.generic.dictionary-2}{Dictionary<TKey, TValue>}?})
называется абстрактный тип данных, хранящий пары <<ключ-значение>> (ключ не может повторяться) и поддерживающий следующие операции:
\begin{enumerate}
  \item \mverb{insert(key, value)}~--- добавляет пару в коллекцию;
  \item \mverb{find(key)}~--- извлекает значение по его ключу;
  \item \verb|delete(key)|~--- удаляет пару по ключу.
\end{enumerate}

С математической точки зрения ассоциативный массив задает конечное отображение из подмножества всех объектов типа ключей в подмножество всех
объектов типа значений.

Разумеется, практический интерес зачастую представляют собой только такие реализации словарей, в которых базовые операции выполняются эффективно~---
по крайней мере логарифмически (в среднем). Такие асимптотические оценки можно получить, используя сбалансированные деревья поиска или,
(о чем речь пойдет далее) хеш-таблицы.

\textbf{Хеш-таблица}~--- это ассоциативный массив, в котором местоположение элемента массива зависит от значения самого элемента.
Связь между значением элемента и его позицией в хеш-таблице задает \textit{хеш-функция}.
Так как при хорошо подобранной хеш-функции вероятность коллизий достаточно мала, хеш-таблицы могут предоставлять функционал ассоциативного массива
со средней временной сложностью $O(1)$, что много лучше $O(\log{n})$ у сбалансированных деревьев поиска. Недостаток хеш-таблиц заключается в
деградации их временной сложности до $O(n)$ с увеличением числа коллизий, вне зависимости от способа их разрешения.

Выбор хеш-функции напрямую влияет на эффективность хеш-таблицы. Хорошая хеш-функция должна распределять значения хешей для всевозможных входных данных равномерно,
быть простой в вычислении и, в идеале, обладать лавинным эффектом. Впрочем помимо этого для минимизации коллизий следует держать хеш-таблицу лишь
частично заполненной ($\alpha = \frac{\text{число ключей в таблице}}{\text{размер таблицы}}, \alpha \leq 0.7$).

Коллизии в хеш-таблице можно \hyperref[sec:hashtable-collisions]{разрешать различными способами}, и это серьезно влияет на внутреннюю
архитектуру структуры данных.

\section{Обработка (разрешение) коллизий хеширования: прямое связывание, ``открытая адресация''}
\label{sec:hashtable-collisions}
Так как хеш является (битовая) строка фиксированной длины, то, вообще говоря, по принципу Дирихле существуют различные данные,
имеющие одинаковый хеш. Поэтому необходима некоторая стратегия разрешения таких <<коллизий>>. На практике используются две стратегии разрешения
коллизий: \textit{метод цепочек} (\textit{прямое связывание}) и \textit{``открытая адресация''}.

\subsection{Метод цепочек} \label{sec:chain_method}

Суть \textit{метода цепочек} заключается в том, что все элементы, попадающие в одну и ту же ячейку хеш-таблицы, хранятся в виде связанного списка (так называемой \textit{цепочки}).

\textbf{Принцип работы:}
\begin{enumerate}[font=\scriptsize, noitemsep, topsep=0pt, , partopsep=0pt]
	\item {\footnotesize \textit{Хеширование ключа}. Ключ обрабатывается хеш-функцией, которая возвращает хеш-код для данного значения.}
	\item {\footnotesize \textit{Обработка коллизий}. Если в ячейке с данным хеш-кодом уже есть элемент, то на этом слоте создается связанный список, в конец которого добавляется новый ключ.}
	\item {\footnotesize \textit{Поиск/удаление элемента}. Вычисляется хеш ключа, находится нужная ячейка, а дальше проводится линейный поиск по цепочке, пока не будет найден элемент с искомым ключом.}
\end{enumerate}
\vspace{5pt}

Временная асимптотическая сложность алгоритма: 
\begin{itemize}[font=\scriptsize, noitemsep, topsep=0pt, , partopsep=0pt]
	\item {\footnotesize Наихудшая сложность поиска: \textit{O(n)}.}
	\item {\footnotesize Наихудшая сложность удаления: \textit{O(n)}.}
\end{itemize}
\vspace{5pt}

\begin{minipage}[t]{0.45\textwidth}
	\textbf{Преимущества метода:}
	\begin{itemize}[leftmargin=*, font=\scriptsize, noitemsep, topsep=0pt, , partopsep=0pt]
		\item {\footnotesize Простота реализации.}
		\item {\footnotesize Эффективен при небольшом количестве коллизий.}
		\item {\footnotesize Не требует перестройки таблицы при добавлении элементов.}
	\end{itemize}
\end{minipage}
\hspace{1cm}
\begin{minipage}[t]{0.45\textwidth}
	\textbf{Недостатки метода:}
	\begin{itemize}[leftmargin=*, font=\scriptsize, noitemsep, topsep=0pt, , partopsep=0pt]
		\item {\footnotesize При большом количестве коллизий списки становятся длинными, из-за чего падает производительность.}
		\item {\footnotesize Затрачивается дополнительная память для хранения указателей на элементы связанных списков.}
	\end{itemize}
\end{minipage}

\subsection{Открытая адресация} \label{sec:open_addressing}

Суть метода \textit{открытой адресации} (или \textit{закрытого хеширования}) заключается в том, что каждый ключ
хранится в хеш-таблице исключительно по своему хеш-коду. Каждому хеш-коду соответствует ровно один ключ в хеш-таблице,
а размер хеш-таблицы всегда больше количества ключей. Если возникает коллизия, алгоритм ищет следующую свободную ячейку
согласно определенной стратегии.
\vspace{5pt}

\begin{minipage}[t]{0.30\textwidth}
	\fontsize{8.5pt}{11pt}\selectfont
	\centerline{\small \textbf{Линейное пробирование}}\par

	Если ячейка занята, то проверяется следующая по порядку:\par
	\vspace{2pt}
	$\boldsymbol{h(k, i) = (h'(k) + i) \ mod \ m}$,\par
	\vspace{2pt}
	где:\par
	$\boldsymbol{h'(k)}$ -- исходная кеш-функция,\par
	$\boldsymbol{i}$ -- номер попытки,\par
	$\boldsymbol{m}$ -- размер таблицы.	

	\vspace{6pt}
	\hrule
	\vspace{6pt}

	Простая реализация, хорошая локальность кэша, но возникает \textit{кластеризация} -- длинные последовательности занятых ячеек, что ухудшает производительность.
\end{minipage}
\hfill
\begin{minipage}[t]{0.30\textwidth}
	\fontsize{8.5pt}{11pt}\selectfont
	\centerline{\small \textbf{Квадратичное пробирование}}\par

	Если ячейка занята, то проверяется следующая по порядку:\par
	\vspace{2pt}
	$\boldsymbol{h(k, i) = (h'(k) +  c_{1}i + c_{2}i^{2}) \ mod \ m}$,\par
	\vspace{2pt}
	где:\par
	$\boldsymbol{c_1, c_2}$ -- константы.

	\vspace{28pt}
	\hrule
	\vspace{6pt}

	Уменьшает кластеризацию по сравнению с линейным преобразованием, но может не найти свободную ячейку, даже если она есть (\textit{циклическое пробирование}).
\end{minipage}
\hfill
\begin{minipage}[t]{0.30\textwidth}
	\fontsize{8.5pt}{11pt}\selectfont
	\centerline{\small \textbf{Двойное хеширование}}\par

	Если ячейка занята, то проверяется следующая по порядку:\par
	\vspace{2pt}
	$\boldsymbol{h(k, i) = (h_{1}(k) +  i*h_{2}(k)) \ mod \ m}$,\par
	\vspace{2pt}
	где:\par
	$\boldsymbol{h_{2}(k)}$ -- вторая хеш-функция, не обращаемая в $0$.

	\vspace{17pt}
	\hrule
	\vspace{6pt}

	Наиболее равномерное распределение ключей по хешам, минимизированная кластеризация, однако требуется вычисление двух хеш-функций.
\end{minipage}
\vspace{10pt}

\textit{Пару слов об асимптотической сложности:}

\begin{itemize}
	\item {\footnotesize Средняя сложность поиска: $O(1)$, худший случай: $O(n)$}
	\item {\footnotesize Средняя сложность удаления: $O(1)$, худший случай: $O(n)$}
\end{itemize}

Так или иначе, в индустрии используются оба подхода:
\href{https://doc.rust-lang.org/std/collections/struct.HashMap.html}{Rust~--- квадратичное пробирование}\footnote{Так написано в документации.},
\href{https://en.cppreference.com/w/cpp/container/unordered_map.html}{С++~--- цепочки} \footnote{По \cppref[стандарту С++]{cpp/container/unordered_map} 
  \begin{quote}
    Internally, the elements are not sorted in any particular order, but organized into buckets. Which bucket an element is placed into depends entirely on the hash of its key. Keys with the same hash code appear in the same bucket.
  \end{quote}
Это буквально естественно ложится на метод цепочек, и почти все современные реализации ее используют.}.

\section{Иерархические списки, деревья. Основные определения, связанные с деревьями}
\section{Бинарные деревья - основные понятия. Основные операции с бинарными деревьями}
\section{Алгоритмы обхода дерева (поиск в неупорядоченном дереве)}
\section{Добавление и удаление элементов дерева}
